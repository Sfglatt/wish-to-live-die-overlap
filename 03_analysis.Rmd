---
title: "03_analysis"
author: "Sglatt"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r packages}
if (!require("dplyr")) {
  install.packages("dplyr")
  require("dplyr")
}
if (!require("janitor")) {
  install.packages("janitor")
  require("janitor")
}
if (!require("psych")) {
  install.packages("psych")
  require("psych")
}
if (!require("yhat")) {
  install.packages("yhat")
  require("yhat")
}
if (!require("apaTables")) {
  install.packages("apaTables")
  require("apaTables")
}
if (!require("lme4")) {
  install.packages("lme4")
  require("lme4")
}
```

# Import dataset
```{r data and dir}
# Import the datasets created in 01_Data
Baseline_data <- read.csv("01_output/Baseline_data_2025-12-19.csv") # Baseline
Temporal_data <- read.csv("01_output/Temporal_data_2025-12-24.csv") # Full (including baseline)

# Make a folder to save the output
if (!dir.exists("03_output")) {
  dir.create("03_output")
}
```

# Wish to Live and Wish to Die descriptive co-occurrence
```{r concurrence}
# Relabel WTL/WTD variables
Baseline_data <- Baseline_data %>%
  dplyr::mutate(
    q01_ssi_label = case_when(
      q01_ssi == 0 ~ "Moderate to strong wish to live",
      q01_ssi == 1 ~ "Weak wish to live",
      q01_ssi == 2 ~ "No wish to live",
      TRUE ~ NA_character_
    ),
    q02_ssi_label = case_when(
      q02_ssi == 0 ~ "No wish to die",
      q02_ssi == 1 ~ "Weak wish to die",
      q02_ssi == 2 ~ "Moderate to strong wish to die",
      TRUE ~ NA_character_
    )
  )

# Table with WTL-WTD responses
tab <- Baseline_data %>%
  tabyl(q01_ssi_label, q02_ssi_label) %>%
  adorn_totals(where = c("row", "col")) %>%
  adorn_percentages("row") %>%
  adorn_pct_formatting(digits = 1) %>%
  adorn_ns()

# Look at it
tab

# Save the  table
tab <- as.data.frame(tab)

write.csv(tab,
  file = paste0(
    "02_output/WTL_WTD_cross_table_",
    format(Sys.Date(), "%Y-%m-%d"), ".csv"
  ),
  row.names = TRUE
)
```

# Covary the WTL out of WTD and the WTD out of WTL
```{r residual vars}
# WTL without WTD
model_WTL_on_WTD <- lm(q01_ssi ~ q02_ssi, data = Baseline_data)
Baseline_data$WTL_unique <- residuals(model_WTL_on_WTD)

# WTD without WTL
model_WTD_on_WTL <- lm(q02_ssi ~ q01_ssi, data = Baseline_data)
Baseline_data$WTD_unique <- residuals(model_WTD_on_WTL)

# Verify
cor(Baseline_data$WTL_unique, Baseline_data$q02_ssi)
cor(Baseline_data$WTD_unique, Baseline_data$q01_ssi)

# Summary
describe(Baseline_data[, c("WTL_unique", "WTD_unique")])

# Reverse-score WTL so higher = stronger wish to live
Baseline_data <- Baseline_data %>%
  mutate(
    q01_ssi_rev = max(q01_ssi, na.rm = TRUE) - q01_ssi
  )

model_WTL_on_WTD_rev <- lm(q01_ssi_rev ~ q02_ssi, data = Baseline_data)
Baseline_data$WTL_unique_rev <- residuals(model_WTL_on_WTD_rev)

# WTD without WTL
model_WTD_on_WTL_rev <- lm(q02_ssi ~ q01_ssi_rev, data = Baseline_data)
Baseline_data$WTD_unique_rev <- residuals(model_WTD_on_WTL_rev)

# Verify
cor(Baseline_data$WTL_unique_rev, Baseline_data$q02_ssi)
cor(Baseline_data$WTD_unique_rev, Baseline_data$q01_ssi_rev)

# Summary
describe(Baseline_data[, c("WTL_unique", "WTL_unique_rev", "WTD_unique", "WTD_unique_rev")])
```

# Isolate the shared variation among WTL/WTD
```{r shared var pca}
# Doing this with principal component analysis
pc <- prcomp(Baseline_data[, c("q01_ssi", "q02_ssi")], scale. = TRUE)

# Create shared variation variable
# Specifically, the first principal component to capture maximal shared variance
Baseline_data$WTL_WTD_shared <- pc$x[, 1]

# Verify correlation with original variables
cor(Baseline_data$WTL_WTD_shared, Baseline_data$q01_ssi)
cor(Baseline_data$WTL_WTD_shared, Baseline_data$q02_ssi)

# Look at descriptives
describe(Baseline_data[, c("WTL_unique", "WTD_unique", "WTL_WTD_shared")])
```


# sensitivity check of shared variation with PCA by using SEM
```{r shared var sem}
if (!require("lavaan")) {
  install.packages("lavaan")
  require("lavaan")
}

# Single-factor model for WTL and WTD
cfa_model <- "
  Shared =~ q01_ssi + q02_ssi
"
fit_cfa <- lavaan::cfa(
  model = cfa_model,
  data = Baseline_data,
  std.lv = TRUE, # fix factor variance
  estimator = "MLR"
)

# Extract factor scores
Baseline_data$WTL_WTD_shared_CFA <- lavPredict(fit_cfa, type = "lv")[, 1]

# Now compare the PCA shared score with the CFA shared score
cor(
  Baseline_data$WTL_WTD_shared,
  Baseline_data$WTL_WTD_shared_CFA,
  use = "pairwise.complete.obs"
)

# Because of nonâ€“positive definite information matrix, constrain to equal loadings
model_cfa_equal <- "
  f =~ 1*q01_ssi + 1*q02_ssi
"
fit_cfa_equal <- lavaan::cfa(
  model_cfa_equal,
  data = Baseline_data,
  ordered = c("q01_ssi", "q02_ssi")
)

summary(fit_cfa_equal, fit.measures = TRUE)
Baseline_data$WTL_WTD_shared_CFA_equal <- lavPredict(fit_cfa_equal)[, 1]

# Correlate CFA and PCA derived shared scores
cor(
  Baseline_data$WTL_WTD_shared,
  Baseline_data$WTL_WTD_shared_CFA_equal
)
```

# Another sensitivity check using PCA on a polychoric correlation matrix
```{r shared var polychoric}
# Polychoric correlation for ordinal WTL/WTD
poly_out <- psych::polychoric(
  Baseline_data[, c("q01_ssi", "q02_ssi")]
)

poly_out$rho

# one-factor extraction from polychoric correlation matrix
fa_poly <- psych::fa(
  r = poly_out$rho,
  nfactors = 1,
  fm = "ml", # maximum likelihood
  rotate = "none"
)

fa_poly

# Get factor scores from polychoric structure
fa_poly_scores <- psych::factor.scores(
  Baseline_data[, c("q01_ssi", "q02_ssi")],
  f = fa_poly,
  method = "Thurstone"
)

Baseline_data$WTL_WTD_shared_poly <- as.numeric(fa_poly_scores$scores)

# Correlate with original PCA
cor(
  Baseline_data$WTL_WTD_shared,
  Baseline_data$WTL_WTD_shared_poly
)
```

# From the unique and shared extractions, create proportions of variance components (=1 for each person) 
```{r dominant proportions}
# Prepare proportions (absolute values)

# Absolute-value table for dominance
tri <- Baseline_data %>%
  dplyr::transmute(
    `WTL Unique` = abs(WTL_unique),
    `Shared Component` = abs(WTL_WTD_shared),
    `WTD Unique` = abs(WTD_unique)
  )

# Assign dominant component (by magnitude)
Baseline_data$Dominant_component <-
  names(tri)[apply(tri, 1, which.max)]

# Look at signed value of the dominant component
Baseline_data$Dominant_signed <- with(
  Baseline_data,
  ifelse(
    Dominant_component == "WTL Unique", WTL_unique,
    ifelse(
      Dominant_component == "WTD Unique", WTD_unique,
      WTL_WTD_shared
    )
  )
)

# Distribution of dominant components
table(Baseline_data$Dominant_component)
prop.table(table(Baseline_data$Dominant_component)) * 100

# Make sure no one had tied scores
rowSums(tri[, 1:3] == apply(tri[, 1:3], 1, max)) > 1
sum(rowSums(tri[, 1:3] == apply(tri[, 1:3], 1, max)) > 1)

# Sign sensitivity check
table(
  Baseline_data$Dominant_component,
  sign(Baseline_data$Dominant_signed)
)
```

# Compare magnitude of unique vs shared variation at the individual level
```{r paired t}
# Create absolute-values of residualized/shared variation
Baseline_data$WTL_unique_abs <- abs(Baseline_data$WTL_unique)
Baseline_data$WTD_unique_abs <- abs(Baseline_data$WTD_unique)
Baseline_data$WTL_WTD_shared_abs <- abs(Baseline_data$WTL_WTD_shared)

# Also make a combined unique score
Baseline_data$Unique_combined_abs <- Baseline_data$WTL_unique_abs + Baseline_data$WTD_unique_abs

# Make a variable for the maximum unique absolute value
Baseline_data$Unique_max_abs <- pmax(
  Baseline_data$WTL_unique_abs,
  Baseline_data$WTD_unique_abs
)


# Look at descriptives
describe(Baseline_data[, c("WTL_unique_abs", "WTD_unique_abs", "Unique_max_abs", "Unique_combined_abs", "WTL_WTD_shared_abs")])

# Paired t-tests
jmv::ttestPS(
  data = Baseline_data,
  pairs = list(
    list(i1 = "WTL_unique_abs", i2 = "WTL_WTD_shared_abs"), # unique WTL vs overlap
    list(i1 = "WTD_unique_abs", i2 = "WTL_WTD_shared_abs"), # unique WTD vs overlap
    list(i1 = "Unique_max_abs", i2 = "WTL_WTD_shared_abs") # maximum absolute value of either unique one vs overlap
  ),
  wilcoxon = TRUE,
  norm = TRUE,
  meanDiff = TRUE,
  ci = TRUE,
  effectSize = TRUE,
  ciES = TRUE
)
```

# Overall model R2/significance for WTL+WTD (raw)
```{r regr concurrent}
# Loop outcomes and regression models
outcomes <- c("bdi", "bhs", "srcs17", "inq_pb", "inq_tb", "rls")

# Regression models for all outcomes
regression_models_1 <- setNames(lapply(outcomes, function(outcome) {
  formula <- as.formula(paste0(outcome, " ~ q01_ssi + q02_ssi"))
  lm(formula, data = Baseline_data)
}), paste0("regression_", outcomes, "_1"))

# Regression objects
list2env(regression_models_1, envir = .GlobalEnv)

summary(regression_models_1[["regression_bdi_1"]])
summary(regression_models_1[["regression_bhs_1"]])
summary(regression_models_1[["regression_srcs17_1"]])
summary(regression_models_1[["regression_inq_pb_1"]])
summary(regression_models_1[["regression_inq_tb_1"]])
summary(regression_models_1[["regression_rls_1"]])

# Check VIF/multicollinearity
olsrr::ols_coll_diag(regression_models_1[["regression_bdi_1"]])
```

# Decompose R2 via commonality analysis 
```{r commonality}
# Loop commonality outcomes
commonality_results_1 <- setNames(lapply(outcomes, function(outcome) {
  commonalityCoefficients(
    Baseline_data,
    outcome,
    list("q01_ssi", "q02_ssi")
  )
}), paste0("commonality_", outcomes, "_1"))

# Commonality results object
list2env(commonality_results_1, envir = .GlobalEnv)

# Look at variance partitions
commonality_results_1[["commonality_bdi_1"]]
commonality_results_1[["commonality_rls_1"]]
commonality_results_1[["commonality_bhs_1"]]
commonality_results_1[["commonality_srcs17_1"]]
commonality_results_1[["commonality_inq_pb_1"]]
commonality_results_1[["commonality_inq_tb_1"]]
```

# Unique + shared variation correlations
Use the residualized and shared variables for correlations with outcomes
```{r resid cors}
# Correlations variables
Corr_vars <- Baseline_data %>%
  dplyr::select(
    q01_ssi, # Raw WTL
    q02_ssi, # Raw WTD
    WTL_unique, # WTL without WTD
    WTD_unique, # WTD without WTL
    WTL_WTD_shared, # WTL-WTD common, without unique
    bdi,
    bhs,
    srcs17,
    inq_pb,
    inq_tb,
    rls
  )

# Correlation table
Corr_table <- apa.cor.table(
  Corr_vars,
  filename = paste0(
    "03_output/Correlations_residuals_",
    format(Sys.Date(), "%Y-%m-%d"), ".doc"
  ),
  table.number = 1,
  show.conf.interval = TRUE,
  show.sig.stars = TRUE,
  landscape = TRUE
)

# Look at at it
Corr_table

# Save the table
Corr_table_df <- as.data.frame(Corr_table$table.body)
write.csv(Corr_table_df, paste0("03_output/Correlations_residuals_", Sys.Date(), ".csv"))

# For exact p
corr_out <- psych::corr.test(
  Corr_vars,
  use = "pairwise",
  adjust = "none"
)

corr_out$p
```

# Power considerations
```{r pwr}
if (!require("pwrss")) {
  install.packages("pwrss")
  require("pwrss")
}
if (!require("pwr")) {
  install.packages("pwr")
  require("pwr")
}

# Power analysis for paired t-test, minimum effect size of interest = 0.2
pwr::pwr.t.test(
  n = 192,
  d = NULL,
  sig.level = 0.05,
  power = .80, type = "paired"
)

# Power analysis for multiple regression total explained variance with 2 predictors, minimum variation of interest = 5%
pwrss::pwrss.f.reg(
  r2 = 0.05, # Minimum R2 of interest
  k = 2, # number of total predictors, WTL and WTD
  n = NULL, # sample size to be calculated
  power = 0.80,
  alpha = 0.05
)

# Power analysis for correlation coefficient (against 0, z-test), minimum correlation of interest = 0.2
pwrss::pwrss.z.corr(
  r = 0.20,
  r0 = 0,
  alpha = 0.05,
  n = NULL,
  power = .80,
  verbose = TRUE
)

# Power analysis for correlation coefficient, minimum correlation of interest = 0.2
pwr::pwr.r.test(n = 192, r = NULL, sig.level = 0.05, power = 0.8)
?pwr.r.test
```

# Sensitivity residualization
```{r sensitivity residuals}
# Rank-transform WTL/WTD
Baseline_data <- Baseline_data %>%
  mutate(
    q01_ssi_rank = rank(q01_ssi, ties.method = "average"),
    q02_ssi_rank = rank(q02_ssi, ties.method = "average")
  )

# Residualize on ranks instead of raw items
model_WTL_rank <- lm(q01_ssi_rank ~ q02_ssi_rank, data = Baseline_data)
Baseline_data$WTL_unique_rank <- residuals(model_WTL_rank)

model_WTD_rank <- lm(q02_ssi_rank ~ q01_ssi_rank, data = Baseline_data)
Baseline_data$WTD_unique_rank <- residuals(model_WTD_rank)

# Shared component from rank PCA
pc_rank <- prcomp(Baseline_data[, c("q01_ssi_rank", "q02_ssi_rank")],
  scale. = TRUE
)
Baseline_data$WTL_WTD_shared_rank <- pc_rank$x[, 1]

# Check convergence with linear residuals
# WTL residuals correlation (lin vs rank)
round(cor(Baseline_data$WTL_unique, Baseline_data$WTL_unique_rank, use = "p"), 5) # 0.980
# WTD residuals correlation (lin vs rank)
round(cor(Baseline_data$WTD_unique, Baseline_data$WTD_unique_rank, use = "p"), 5) # 0.992
# Shared correlation (PCA vs rank PCA)
round(cor(Baseline_data$WTL_WTD_shared, Baseline_data$WTL_WTD_shared_rank, use = "p"), 5) # 0.994
```

# correlations sensitivity
Use polyserial correlations for raw/residualized/shared correlations 
```{r polyserial}
outcomes <- c("bdi", "bhs", "srcs17", "inq_pb", "inq_tb", "rls")

if (!require("polycor")) {
  install.packages("polycor")
  require("polycor")
}

cor_results <- lapply(outcomes, function(out) {
  # Pearson correlations
  pearson_WTL_raw <- cor(Baseline_data$q01_ssi, Baseline_data[[out]], use = "pairwise.complete.obs", method = "pearson")
  pearson_WTD_raw <- cor(Baseline_data$q02_ssi, Baseline_data[[out]], use = "pairwise.complete.obs", method = "pearson")
  pearson_WTL_resid <- cor(Baseline_data$WTL_unique, Baseline_data[[out]], use = "pairwise.complete.obs", method = "pearson")
  pearson_WTD_resid <- cor(Baseline_data$WTD_unique, Baseline_data[[out]], use = "pairwise.complete.obs", method = "pearson")
  pearson_shared <- cor(Baseline_data$WTL_WTD_shared, Baseline_data[[out]], use = "pairwise.complete.obs", method = "pearson")

  # Polyserial correlations
  # First variable needs to be continuous, second one needs to be ordinal (or is treated as such)
  polyserial_WTL_raw <- polycor::polyserial(Baseline_data[[out]], Baseline_data$q01_ssi, ML = TRUE)
  polyserial_WTD_raw <- polycor::polyserial(Baseline_data[[out]], Baseline_data$q02_ssi, ML = TRUE)
  polyserial_WTL_resid <- polycor::polyserial(Baseline_data[[out]], Baseline_data$WTL_unique, ML = TRUE)
  polyserial_WTD_resid <- polycor::polyserial(Baseline_data[[out]], Baseline_data$WTD_unique, ML = TRUE)
  polyserial_shared <- polycor::polyserial(Baseline_data[[out]], Baseline_data$WTL_WTD_shared, ML = TRUE)

  data.frame(
    outcome = out,
    # Pearsons vs polyserial for raw WTL
    pearson_WTL_raw,
    polyserial_WTL_raw,
    # Pearsons vs polyserial for raw WTD
    pearson_WTD_raw,
    polyserial_WTD_raw,
    # Pearsons vs polyserial for residualized WTL
    pearson_WTL_resid,
    polyserial_WTL_resid,
    # Pearsons vs polyserial for residualized WTD
    pearson_WTD_resid,
    polyserial_WTD_resid,
    # Pearsons vs polyserial for shared component
    pearson_shared,
    polyserial_shared
  )
})

cor_results_df <- do.call(rbind, cor_results)
cor_results_df

# check how Pearson and Polyserial estimates accord
cor(cor_results_df$pearson_WTL_raw, cor_results_df$polyserial_WTL_raw)
cor(cor_results_df$pearson_WTD_raw, cor_results_df$polyserial_WTD_raw)
cor(cor_results_df$pearson_WTL_resid, cor_results_df$polyserial_WTL_resid)
cor(cor_results_df$pearson_WTD_resid, cor_results_df$polyserial_WTD_resid)
cor(cor_results_df$pearson_shared, cor_results_df$polyserial_shared)
```

# Longitudinal models of shared vs unique WTL/WTD variation
```{r residualize and pca temporal}
# Residualize per timepoint
Temporal_data <- Temporal_data %>%
  group_by(month) %>%
  mutate(
    WTL_unique = residuals(lm(q01_ssi ~ q02_ssi, na.action = na.exclude)),
    WTD_unique = residuals(lm(q02_ssi ~ q01_ssi, na.action = na.exclude))
  ) %>%
  ungroup()

# Extract shared component per timepoint 
Temporal_data <- Temporal_data %>%
  group_by(month) %>%
  mutate(
    shared = {
      temp <- cbind(q01_ssi, q02_ssi)
      complete_idx <- complete.cases(temp)
      pc <- prcomp(temp[complete_idx, ], scale. = TRUE)  
      shared_vec <- rep(NA, n()) # Deal with missing
      shared_vec[complete_idx] <- pc$x[,1]
      shared_vec
    }
  ) %>%
  ungroup()

# Sanity check 
# Make sure the residualized WTL/WTD and PCA at baseline match what was done above
baseline_check <- Temporal_data %>%
  filter(month == 0) %>%
  select(id, WTL_unique, WTD_unique, shared) %>%
  left_join(
    Baseline_data %>%
      select(id, WTL_unique, WTD_unique, WTL_WTD_shared),
    by = "id",
    suffix = c("_temporal", "_baseline")
  )

baseline_check %>%
  summarise(
    cor_WTL = cor(WTL_unique_temporal, WTL_unique_baseline, use = "pairwise.complete.obs"),
    cor_WTD = cor(WTD_unique_temporal, WTD_unique_baseline, use = "pairwise.complete.obs"),
    cor_shared = cor(shared, WTL_WTD_shared, use = "pairwise.complete.obs")
  ) # Good
```

# Multilevel models 
```{r mlms}
# Shared component
model_shared <- lmer(shared ~ 1 + (1 | id), data = Temporal_data)

# WTL_unique  
model_WTL_unique <- lmer(WTL_unique ~ 1 + (1 | id), data = Temporal_data)

# WTD_unique
model_WTD_unique <- lmer(WTD_unique ~ 1 + (1 | id), data = Temporal_data)

# Model summaries 
summary(model_shared)
summary(model_WTL_unique) 
summary(model_WTD_unique)

# Variance components table
r2(model_shared)      
icc(model_shared)     
VarCorr(model_shared)

# Results table (random effects only)
sjPlot::tab_model(
  model_shared, model_WTD_unique, model_WTL_unique
)
```

# Save baseline dataset with new variables
- residualized WTD/WTL, 
- rank-transformed WTL/WTD and those residuals; 
- the shared PCA component (raw and from rank-transformed), 
- absolute values of residualized WTD/WTL + shared PCA component
- dominant component of absolute values

# Save longitudinal dataset with new variables
- residualized WTD/WTL (each timepoint)
- shared PCA component (each timepoint)
  
```{r save data}
# Baseline
write.csv(Baseline_data,
  file = paste0(
    "02_output/Baseline_data_vars_",
    format(Sys.Date(), "%Y-%m-%d"), ".csv"
  ),
  row.names = TRUE
)

# Temporal
write.csv(Temporal_data,
  file = paste0(
    "02_output/Temporal_data_vars_",
    format(Sys.Date(), "%Y-%m-%d"), ".csv"
  ),
  row.names = TRUE
)
```

# Citations
```{r cites}
report::report(sessionInfo())
```


